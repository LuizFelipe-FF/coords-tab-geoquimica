{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPRnwHzEtvbE2rsKNd0fKxX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LuizFelipe-FF/coords-tab-geoquimica/blob/main/Espacializa%C3%A7%C3%A3o_Tabela_Geoqu%C3%ADmica.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "___\n",
        "*Autor: Luiz Felipe Franco Ferreira - Graduando em Geologia*\n",
        "\n",
        "*Atividade: Seleção de dados e criação de um SHP*\n",
        "\n",
        "*Data: 18/06/2025*\n",
        "\n",
        "*Resumo: Código desenvolvido para garantir ID's únicos para cada amostra, padronizar os diversos tipos de coordenadas,criação de um Geodataframe agrupando as amostras que possuam Lat e Long, e gerar um SHP.*\n",
        "___"
      ],
      "metadata": {
        "id": "K94E53cH_kJf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Etapas:\n",
        "1. Padronização dos ID's\n",
        "2. Padronização das Coords\n",
        "3. Criação do GeoDataFrame"
      ],
      "metadata": {
        "id": "ykN2WRdUHeF5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "from shapely.geometry import Point\n",
        "from pyproj import Proj\n",
        "import re"
      ],
      "metadata": {
        "id": "n6xOLw2YBUg7"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1. Padronização dos ID's\n",
        "Impede de aparecer o mesmo ID para amostras distintas, criando assim a coluna sample name unique adicionando sufixos aos ID's."
      ],
      "metadata": {
        "id": "YpcKpGXQm04t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Nq5Co3d88_Se"
      },
      "outputs": [],
      "source": [
        "# 1. Carregar CSV\n",
        "df = pd.read_csv(\"pmp_recalculated.csv\", sep=';')\n",
        "\n",
        "# 2. Nomes únicos para amostras\n",
        "def make_unique_names(series):\n",
        "    counts = {}\n",
        "    unique_names = []\n",
        "    for name in series:\n",
        "        if pd.isna(name):\n",
        "            unique_names.append(name)\n",
        "            continue\n",
        "        count = counts.get(name, 0)\n",
        "        suffix = '' if count == 0 else f'_{chr(96 + count + 1)}'\n",
        "        unique_names.append(f\"{name}{suffix}\")\n",
        "        counts[name] = count + 1\n",
        "    return unique_names\n",
        "\n",
        "df['sample_name_unique'] = make_unique_names(df['sample_name'])\n",
        "\n",
        "# 3. Expandir casos com \"and\" e \"/\"\n",
        "def expand_multiple_coordinates(df):\n",
        "    rows = []\n",
        "    for _, row in df.iterrows():\n",
        "        coord_str = str(row['longitude'])\n",
        "        if 'and' in coord_str and '/' in coord_str:\n",
        "            pairs = [pair.strip() for pair in coord_str.split('and')]\n",
        "            for i, pair in enumerate(pairs):\n",
        "                try:\n",
        "                    easting_raw, northing_raw = pair.split('/')\n",
        "                    new_row = row.copy()\n",
        "                    new_row['lon_raw'] = easting_raw.strip()\n",
        "                    new_row['lat_raw'] = northing_raw.strip()\n",
        "                    new_row['sample_name_unique'] += f\"_{chr(97 + i)}\"\n",
        "                    rows.append(new_row)\n",
        "                except:\n",
        "                    continue\n",
        "        else:\n",
        "            new_row = row.copy()\n",
        "            new_row['lat_raw'] = str(row['latitude'])\n",
        "            new_row['lon_raw'] = str(row['longitude'])\n",
        "            rows.append(new_row)\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "df_expanded = expand_multiple_coordinates(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2. Padronização das Coords\n",
        "Identifica as variações de tipos de coordeandas, padroniza como decimal e corrige erros para manter os dados espacializados na região sul do brasil."
      ],
      "metadata": {
        "id": "6RVeG_LHmyOz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Conversão UTM para DD\n",
        "def try_utm_to_dd(northing, easting, zone=22, hemisphere='south'):\n",
        "    try:\n",
        "        proj = Proj(proj='utm', zone=zone, south=(hemisphere == 'south'), ellps='WGS84')\n",
        "        lon, lat = proj(float(easting), float(northing), inverse=True)\n",
        "        return lat, lon\n",
        "    except:\n",
        "        return None, None\n",
        "\n",
        "# 5. Detecta se valor é UTM\n",
        "def is_probably_utm(value):\n",
        "    try:\n",
        "        num = float(str(value).replace(',', '.').replace(' ', ''))\n",
        "        return 1000000 < num < 10000000\n",
        "    except:\n",
        "        return False\n",
        "\n",
        "# 6. Conversão genérica para decimal\n",
        "def convert_to_decimal(coord):\n",
        "    try:\n",
        "        coord = str(coord).replace('?', '0').replace(',', '.').strip()\n",
        "\n",
        "        # 6.1 Hemisfério com símbolo, espaço ou não\n",
        "        match = re.match(r'(\\d+(?:\\.\\d+)?)\\s*°?\\s*([NSEW])', coord, re.IGNORECASE)\n",
        "        if match:\n",
        "            value = float(match.group(1))\n",
        "            hemisphere = match.group(2).upper()\n",
        "            if hemisphere in ['S', 'W']:\n",
        "                value = -value\n",
        "            return value\n",
        "\n",
        "        # 6.2 Decimal direto\n",
        "        if re.match(r'^-?\\d+(\\.\\d+)?$', coord):\n",
        "            return float(coord)\n",
        "\n",
        "        # 6.3 DMS\n",
        "        dms = re.findall(r'-?\\d+', coord)\n",
        "        if len(dms) >= 3:\n",
        "            d, m, s = map(float, dms[:3])\n",
        "            if not (0 <= m < 60 and 0 <= s < 60):\n",
        "                return None\n",
        "            dd = abs(d) + m / 60 + s / 3600\n",
        "            return -dd if '-' in coord else dd\n",
        "\n",
        "        # 6.4 DM\n",
        "        elif len(dms) == 2:\n",
        "            d, m = map(float, dms)\n",
        "            if not (0 <= m < 60):\n",
        "                return None\n",
        "            dd = abs(d) + m / 60\n",
        "            return -dd if '-' in coord else dd\n",
        "\n",
        "        return None\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "# 7. Conversão linha a linha\n",
        "def smart_coord_conversion(row):\n",
        "    lat_raw = str(row['lat_raw']).replace(' ', '')\n",
        "    lon_raw = str(row['lon_raw']).replace(' ', '')\n",
        "\n",
        "    lat_dec = convert_to_decimal(lat_raw)\n",
        "    lon_dec = convert_to_decimal(lon_raw)\n",
        "\n",
        "    # Correção de sinal faltando para valores que parecem do Brasil\n",
        "    if lat_dec and lat_dec > 0 and lat_dec < 34:\n",
        "        lat_dec = -lat_dec\n",
        "    if lon_dec and lon_dec > 0 and lon_dec < 60:\n",
        "        lon_dec = -lon_dec\n",
        "\n",
        "    # Se ainda falhar, tenta UTM\n",
        "    if (lat_dec is None or lon_dec is None) and is_probably_utm(lat_raw) and is_probably_utm(lon_raw):\n",
        "        try:\n",
        "            northing = float(re.sub(r'[^\\d.]', '', lat_raw))\n",
        "            easting = float(re.sub(r'[^\\d.]', '', lon_raw))\n",
        "            lat_dec, lon_dec = try_utm_to_dd(northing, easting)\n",
        "        except:\n",
        "            lat_dec, lon_dec = None, None\n",
        "\n",
        "    return pd.Series({'lat_dd': lat_dec, 'lon_dd': lon_dec})\n",
        "\n",
        "# 8. Aplicar conversão\n",
        "df_coords = df_expanded.apply(smart_coord_conversion, axis=1)\n",
        "df_final = pd.concat([df_expanded, df_coords], axis=1)\n",
        "\n",
        "# 9. Remover coordenadas inválidas\n",
        "df_final = df_final.dropna(subset=['lat_dd', 'lon_dd'])\n",
        "\n",
        "# 9.1 Filtrar apenas para a região sul do Brasil\n",
        "df_final = df_final[\n",
        "    df_final['lat_dd'].between(-34, -23) &\n",
        "    df_final['lon_dd'].between(-57, -47)\n",
        "]\n",
        "# 9.2 Garantir que só amostras com lat/long válidas entrem no GeoDataFrame\n",
        "df_final = df_final[df_final['lat_dd'].notnull() & df_final['lon_dd'].notnull()]\n"
      ],
      "metadata": {
        "id": "1W9UKpYiBUtC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3. Criação do GeoDataFrame\n",
        "Gera a coluna geometry necessária para espacialização e salva os dados em formato shapefile."
      ],
      "metadata": {
        "id": "A7-kYuBsmwoD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. Criar GeoDataFrame\n",
        "geometry = [Point(xy) for xy in zip(df_final['lon_dd'], df_final['lat_dd'])]\n",
        "gdf = gpd.GeoDataFrame(df_final, geometry=geometry, crs='EPSG:4326')\n",
        "\n",
        "# 11. Exportar para shapefile\n",
        "gdf.to_file(\"dados_convertidos.shp\", driver=\"ESRI Shapefile\", encoding=\"utf-8\")\n",
        "\n",
        "# 12. Visualizar as primeiras linhas\n",
        "print(gdf[['sample_name_unique', 'lat_dd', 'lon_dd', 'geometry']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpYJGdvkYQGG",
        "outputId": "aeb384e3-3d34-4d20-ae37-48e708ba897d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-6-560822401.py:6: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
            "  gdf.to_file(\"dados_convertidos.shp\", driver=\"ESRI Shapefile\", encoding=\"utf-8\")\n",
            "/usr/local/lib/python3.11/dist-packages/pyogrio/raw.py:723: RuntimeWarning: Normalized/laundered field name: 'sample_name' to 'sample_nam'\n",
            "  ogr_write(\n",
            "/usr/local/lib/python3.11/dist-packages/pyogrio/raw.py:723: RuntimeWarning: Normalized/laundered field name: 'suite_by_autor' to 'suite_by_a'\n",
            "  ogr_write(\n",
            "/usr/local/lib/python3.11/dist-packages/pyogrio/raw.py:723: RuntimeWarning: Normalized/laundered field name: 'classification_peate92' to 'classifica'\n",
            "  ogr_write(\n",
            "/usr/local/lib/python3.11/dist-packages/pyogrio/raw.py:723: RuntimeWarning: Normalized/laundered field name: 'classification_peate97' to 'classifi_1'\n",
            "  ogr_write(\n",
            "/usr/local/lib/python3.11/dist-packages/pyogrio/raw.py:723: RuntimeWarning: Normalized/laundered field name: 'localization' to 'localizati'\n",
            "  ogr_write(\n",
            "/usr/local/lib/python3.11/dist-packages/pyogrio/raw.py:723: RuntimeWarning: Normalized/laundered field name: '87Sr/86Sr_m' to '87Sr/86Sr_'\n",
            "  ogr_write(\n",
            "/usr/local/lib/python3.11/dist-packages/pyogrio/raw.py:723: RuntimeWarning: Normalized/laundered field name: '87Sr/86Sr_r' to '87Sr/86S_1'\n",
            "  ogr_write(\n",
            "/usr/local/lib/python3.11/dist-packages/pyogrio/raw.py:723: RuntimeWarning: Normalized/laundered field name: '143Nd/144Nd_m' to '143Nd/144N'\n",
            "  ogr_write(\n",
            "/usr/local/lib/python3.11/dist-packages/pyogrio/raw.py:723: RuntimeWarning: Normalized/laundered field name: '143Nd/144Nd_r' to '143Nd/14_1'\n",
            "  ogr_write(\n",
            "/usr/local/lib/python3.11/dist-packages/pyogrio/raw.py:723: RuntimeWarning: Normalized/laundered field name: '206Pb/204Pb_m' to '206Pb/204P'\n",
            "  ogr_write(\n",
            "/usr/local/lib/python3.11/dist-packages/pyogrio/raw.py:723: RuntimeWarning: Normalized/laundered field name: '206Pb/204Pb_r' to '206Pb/20_1'\n",
            "  ogr_write(\n",
            "/usr/local/lib/python3.11/dist-packages/pyogrio/raw.py:723: RuntimeWarning: Normalized/laundered field name: '207Pb/204Pb_m' to '207Pb/204P'\n",
            "  ogr_write(\n",
            "/usr/local/lib/python3.11/dist-packages/pyogrio/raw.py:723: RuntimeWarning: Normalized/laundered field name: '207Pb/204Pb_r' to '207Pb/20_1'\n",
            "  ogr_write(\n",
            "/usr/local/lib/python3.11/dist-packages/pyogrio/raw.py:723: RuntimeWarning: Normalized/laundered field name: '208Pb/204Pb_m' to '208Pb/204P'\n",
            "  ogr_write(\n",
            "/usr/local/lib/python3.11/dist-packages/pyogrio/raw.py:723: RuntimeWarning: Normalized/laundered field name: '208Pb/204Pb_r' to '208Pb/20_1'\n",
            "  ogr_write(\n",
            "/usr/local/lib/python3.11/dist-packages/pyogrio/raw.py:723: RuntimeWarning: Normalized/laundered field name: 'sample_name_unique' to 'sample_n_1'\n",
            "  ogr_write(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    sample_name_unique  lat_dd  lon_dd              geometry\n",
            "433             GB17B   -28.36   -49.6  POINT (-49.6 -28.36)\n",
            "434              GB16   -28.36   -49.6  POINT (-49.6 -28.36)\n",
            "435             GB25A   -28.36   -49.6  POINT (-49.6 -28.36)\n",
            "436               GB8   -28.36   -49.6  POINT (-49.6 -28.36)\n",
            "437              GB15   -28.36   -49.6  POINT (-49.6 -28.36)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "txw2RzGDBU_C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}